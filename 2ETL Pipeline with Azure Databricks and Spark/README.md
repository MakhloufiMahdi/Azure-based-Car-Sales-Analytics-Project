This ETL pipeline leverages Azure Databricks and Apache Spark to perform advanced data processing on car sales data stored in Azure Blob Storage. The pipeline begins by reading the CSV file using Sparkâ€™s distributed engine, followed by a series of data cleaning steps including null value removal, duplicate elimination, and column normalization (e.g., trimming whitespace, converting text to lowercase). It then enriches the dataset by calculating derived metrics such as car age, average price per brand, and transmission type counts. Additionally, it extracts the top 10 most expensive cars for targeted analysis. The final dataset is securely written to an Azure SQL Database using JDBC, with credentials managed via Azure Key Vault (dbutils.secrets). This pipeline is optimized for large-scale data and supports complex transformations, making it ideal for analytical workloads and machine learning integration.
